{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Задача"
      ],
      "metadata": {
        "id": "UN3k19en-9E3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Реализовать класс `MyBinaryLogisticRegression` для работы с логистической регрессией. Обеспечить возможность использования `l1`, `l2` и `l1l2` регуляризации и реализовать слудующие методы решения оптимизационной задачи:\n",
        "\n",
        "*   Градиентный спуск\n",
        "*   Стохастический градиентный спуск\n",
        "*   Метод Ньютона\n",
        "\n",
        "Обосновать применимость/не применимость того или иного метода оптимизации в случае использованного типа регуляризации.\n",
        "\n"
      ],
      "metadata": {
        "id": "vpw0GFHuFgTB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import warnings"
      ],
      "metadata": {
        "id": "codsbBsYw624"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "fG8aIDIx-rJw"
      },
      "outputs": [],
      "source": [
        "class MyBinaryLogisticRegression:\n",
        "    def __init__(self, l1_ratio=0.0, alpha=0.01, solver='gd',\n",
        "                 iters=1000, lr=0.1, tol=1e-4):\n",
        "        \"\"\"\n",
        "        l1_ratio: 0 - L2, 1 - L1, (0, 1) - Elastic Net\n",
        "        alpha: сила регуляризации\n",
        "        solver: 'gd', 'sgd', 'newton'\n",
        "        \"\"\"\n",
        "        self.l1_ratio = l1_ratio\n",
        "        self.alpha = alpha\n",
        "        self.solver = solver\n",
        "        self.iters = iters\n",
        "        self.lr = lr\n",
        "        self.tol = tol\n",
        "        self.coefs_ = None\n",
        "        self.intercept_ = None\n",
        "        self.feature_names_in_ = None\n",
        "\n",
        "    def _sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-np.clip(z, -250, 250)))\n",
        "\n",
        "    def _get_reg_term(self, w):\n",
        "        w_for_reg = np.copy(w)\n",
        "        w_for_reg[0] = 0\n",
        "\n",
        "        l1_grad = self.l1_ratio * self.alpha * np.sign(w_for_reg)\n",
        "        l2_grad = (1 - self.l1_ratio) * self.alpha * w_for_reg\n",
        "        return l1_grad + l2_grad\n",
        "\n",
        "    def fit(self, X: pd.DataFrame, y: pd.Series):\n",
        "        self.feature_names_in_ = X.columns.tolist()\n",
        "        X_matrix = X.values\n",
        "        y_matrix = y.values.reshape(-1, 1)\n",
        "\n",
        "        n_samples, n_features = X_matrix.shape\n",
        "        weights = np.zeros((n_features + 1, 1))\n",
        "        X_inc = np.hstack([np.ones((n_samples, 1)), X_matrix])\n",
        "\n",
        "        if self.solver == 'gd':\n",
        "            weights = self._gradient_descent(X_inc, y_matrix, weights)\n",
        "        elif self.solver == 'sgd':\n",
        "            weights = self._stochastic_gradient_descent(X_inc, y_matrix, weights)\n",
        "        elif self.solver == 'newton':\n",
        "            weights = self._newton_method(X_inc, y_matrix, weights)\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown solver: {self.solver}\")\n",
        "\n",
        "        self.intercept_ = weights[0].item()\n",
        "        self.coefs_ = weights[1:].flatten()\n",
        "\n",
        "    def _gradient_descent(self, X, y, w):\n",
        "        for i in range(self.iters):\n",
        "            z = X @ w\n",
        "            h = self._sigmoid(z)\n",
        "            gradient = (X.T @ (h - y)) / len(y)\n",
        "\n",
        "            gradient += self._get_reg_term(w)\n",
        "\n",
        "            new_w = w - self.lr * gradient\n",
        "            if np.linalg.norm(new_w - w) < self.tol:\n",
        "                break\n",
        "            w = new_w\n",
        "        return w\n",
        "\n",
        "    def _stochastic_gradient_descent(self, X, y, w):\n",
        "        n = len(y)\n",
        "        for epoch in range(self.iters):\n",
        "            indices = np.random.permutation(n)\n",
        "            X_shuffled = X[indices]\n",
        "            y_shuffled = y[indices]\n",
        "\n",
        "            for i in range(n):\n",
        "                xi = X_shuffled[i:i+1]\n",
        "                yi = y_shuffled[i:i+1]\n",
        "\n",
        "                h = self._sigmoid(xi @ w)\n",
        "                gradient = xi.T @ (h - yi)\n",
        "\n",
        "                gradient += self._get_reg_term(w)\n",
        "\n",
        "                new_w = w - self.lr * gradient\n",
        "                if np.linalg.norm(new_w - w) < self.tol / n:\n",
        "                    break\n",
        "                w = new_w\n",
        "            else:\n",
        "                continue\n",
        "            break\n",
        "        return w\n",
        "\n",
        "    def _newton_method(self, X, y, w):\n",
        "        if self.l1_ratio > 0:\n",
        "            warnings.warn(\"Newton's method is not directly suited for L1 regularization. \"\n",
        "                          \"Only the L2 part of Elastic Net will be included in the Hessian matrix.\")\n",
        "\n",
        "        for i in range(self.iters):\n",
        "            z = X @ w\n",
        "            h = self._sigmoid(z)\n",
        "\n",
        "\n",
        "            gradient = (X.T @ (h - y)) / len(y)\n",
        "            gradient += self._get_reg_term(w)\n",
        "\n",
        "\n",
        "            diag_vec = (h * (1 - h)).flatten()\n",
        "            H = (X.T * diag_vec) @ X / len(y)\n",
        "\n",
        "            reg_matrix = np.eye(w.shape[0]) * (1 - self.l1_ratio) * self.alpha\n",
        "            reg_matrix[0, 0] = 0\n",
        "            H += reg_matrix\n",
        "\n",
        "            try:\n",
        "                step = np.linalg.solve(H, gradient)\n",
        "                new_w = w - step\n",
        "            except np.linalg.LinAlgError:\n",
        "                warnings.warn(\"Hessian matrix is singular, stopping Newton's method.\")\n",
        "                break # Если матрица вырождена\n",
        "\n",
        "            if np.linalg.norm(new_w - w) < self.tol:\n",
        "                break\n",
        "            w = new_w\n",
        "        return w\n",
        "\n",
        "    def predict_proba(self, X: np.array):\n",
        "        if X.ndim == 1:\n",
        "            X = X.reshape(1, -1)\n",
        "\n",
        "        X_inc = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "        weights_full = np.concatenate([np.array([self.intercept_]), self.coefs_]).reshape(-1, 1)\n",
        "        return self._sigmoid(X_inc @ weights_full)\n",
        "\n",
        "    def predict(self, X: np.array):\n",
        "        return (self.predict_proba(X) >= 0.5).astype(int).flatten()\n",
        "\n",
        "    def score(self, X: np.array, y: np.array):\n",
        "        y_pred = self.predict(X)\n",
        "        return accuracy_score(y, y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1. Градиентный спуск (GD):**\n",
        "\n",
        "  •  Применимость: Универсален.\n",
        "  \n",
        "  •  L2: Работает идеально, так как градиент 2w определен везде.\n",
        "\n",
        "  •  L1: Функция |w| не дифференцируема в нуле. Мы используем субградиент (np.sign(w)). В точке 0 производная не определена, поэтому GD может \"колебаться\" около нуля, но для практических задач этого достаточно.\n",
        "\n",
        "**2. Стохастический градиентный спуск (SGD):**\n",
        "\n",
        "  •  Применимость: Лучший выбор для огромных датасетов.\n",
        "\n",
        "  •  L1/L2: Применим аналогично GD. Из-за шума обновлений на каждом объекте SGD еще сложнее сойтись в точный ноль при L1, поэтому веса могут быть \"почти нулевыми\", но не зануляться идеально без специальных проксимальных операторов.\n",
        "\n",
        "**3. Метод Ньютона (Newton):**\n",
        "\n",
        "  •  Применимость: Очень быстрая сходимость (за 5-10 итераций) на гладких функциях.\n",
        "\n",
        "  •  L2: Идеально. Вторая производная L2-штрафа — это константа (α), которая просто добавляется к диагонали Гессиана (Ridge-регуляризация), что делает матрицу более устойчивой (обусловленной).\n",
        "\n",
        "  •  L1: Не применим в классическом виде. Вторая производная |w| равна 0 везде, кроме точки 0, где она не существует. Метод Ньютона полагается на аппроксимацию функции параболой, а функция с L1-штрафом имеет \"излом\". Для L1 обычно используют Coordinate Descent или Proximal Newton Methods.\n"
      ],
      "metadata": {
        "id": "E1kf160mG4wN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Продемонстрировать применение реализованного класса на датасете про пингвинов (целевая переменная — вид пингвина). Рассмотреть все возможные варианты (регуляризация/оптимизация). Для категориального признака `island` реализовать самостоятельно преобразование `Target Encoder`, сравнить результаты классификации с `one-hot`. В качестве метрики использовать `f1-score`."
      ],
      "metadata": {
        "id": "LpjHEiKgGmbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-EPK9_BP92J6",
        "outputId": "2e3cd8e7-1b9d-4ae8-e861-43d4390499d0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('/content/drive/MyDrive/магистратура/1 сем/матстат/лабы/lab5/penguins_binary_classification.csv')"
      ],
      "metadata": {
        "id": "GIAS-ePjxJzY"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q6MDDXvMBMFq",
        "outputId": "34d57a6b-559a-41c2-8fd4-e2f43db7f2bb"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['species', 'island', 'bill_length_mm', 'bill_depth_mm',\n",
              "       'flipper_length_mm', 'body_mass_g', 'year'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    df = pd.read_csv('penguins.csv')\n",
        "except FileNotFoundError:\n",
        "    print(\"penguins.csv not found, using a sample DataFrame structure for demonstration.\")\n",
        "    data = {\n",
        "        'species': np.random.choice(['Adelie', 'Gentoo', 'Chinstrap'], 300),\n",
        "        'island': np.random.choice(['Torgersen', 'Biscoe', 'Dream'], 300),\n",
        "        'bill_length_mm': np.random.rand(300) * 20 + 30,\n",
        "        'bill_depth_mm': np.random.rand(300) * 10 + 10,\n",
        "        'flipper_length_mm': np.random.rand(300) * 50 + 170,\n",
        "        'body_mass_g': np.random.rand(300) * 2000 + 3000,\n",
        "        'sex': np.random.choice(['MALE', 'FEMALE', np.nan], 300, p=[0.45, 0.45, 0.1]),\n",
        "        'year': np.random.choice([2007, 2008, 2009], 300)\n",
        "    }\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "df = df.dropna()\n",
        "\n",
        "original_len = len(df)\n",
        "df = df[df['species'].isin(['Adelie', 'Gentoo'])].copy()\n",
        "if len(df) == 0:\n",
        "    raise ValueError(\"No 'Adelie' or 'Gentoo' species found after filtering. Please check your dataset.\")\n",
        "\n",
        "df['target'] = (df['species'] == 'Gentoo').astype(int)\n",
        "\n",
        "if df['year'].nunique() == 1:\n",
        "    X_cols = [col for col in df.columns if col not in ['species', 'target', 'year']]\n",
        "else:\n",
        "    X_cols = [col for col in df.columns if col not in ['species', 'target']]\n",
        "\n",
        "X = df[X_cols]\n",
        "y = df['target']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "233SfONr-_nX",
        "outputId": "883e937f-c9e5-4345-d43b-f756d907243e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "penguins.csv not found, using a sample DataFrame structure for demonstration.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyTargetEncoder:\n",
        "    def __init__(self):\n",
        "        self.mapping = {}\n",
        "        self.global_mean = 0\n",
        "\n",
        "    def fit(self, column, target):\n",
        "        self.global_mean = target.mean()\n",
        "        self.mapping = target.groupby(column).mean().to_dict()\n",
        "\n",
        "    def transform(self, column):\n",
        "        return column.map(self.mapping).fillna(self.global_mean)\n",
        "\n",
        "\n",
        "def prepare_data(df_input, y_target, encoding_type='ohe'):\n",
        "    df_proc = df_input.copy()\n",
        "\n",
        "    if 'sex' in df_proc.columns:\n",
        "        df_proc['sex'] = (df_proc['sex'] == 'MALE').astype(int)\n",
        "\n",
        "    if 'island' in df_proc.columns:\n",
        "        if encoding_type == 'target':\n",
        "            te = MyTargetEncoder()\n",
        "            te.fit(df_proc['island'], y_target)\n",
        "            df_proc['island'] = te.transform(df_proc['island'])\n",
        "        else:\n",
        "            df_proc = pd.get_dummies(df_proc, columns=['island'], drop_first=True, dtype=int)\n",
        "\n",
        "    return df_proc"
      ],
      "metadata": {
        "id": "j4Ag_IdmGZJY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_raw, X_test_raw, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_ohe = prepare_data(X_train_raw, y_train, encoding_type='ohe')\n",
        "X_test_ohe = prepare_data(X_test_raw, y_test, encoding_type='ohe')\n",
        "\n",
        "X_train_te = prepare_data(X_train_raw, y_train, encoding_type='target')\n",
        "X_test_te = prepare_data(X_test_raw, y_test, encoding_type='target')\n",
        "\n",
        "scaler_ohe = StandardScaler()\n",
        "X_train_ohe_scaled = pd.DataFrame(scaler_ohe.fit_transform(X_train_ohe), columns=X_train_ohe.columns, index=X_train_ohe.index)\n",
        "X_test_ohe_scaled = pd.DataFrame(scaler_ohe.transform(X_test_ohe), columns=X_test_ohe.columns, index=X_test_ohe.index)\n",
        "\n",
        "scaler_te = StandardScaler()\n",
        "X_train_te_scaled = pd.DataFrame(scaler_te.fit_transform(X_train_te), columns=X_train_te.columns, index=X_train_te.index)\n",
        "X_test_te_scaled = pd.DataFrame(scaler_te.transform(X_test_te), columns=X_test_te.columns, index=X_test_te.index)"
      ],
      "metadata": {
        "id": "nmLV43QOGkYw"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['gd', 'sgd', 'newton']\n",
        "reg_types = {\n",
        "    'l2': 0.0,\n",
        "    'l1': 1.0,\n",
        "    'l1l2': 0.5\n",
        "}\n",
        "\n",
        "results = []\n",
        "\n",
        "for enc_name, X_train_scaled, X_test_scaled in [('OHE', X_train_ohe_scaled, X_test_ohe_scaled),\n",
        "                                                ('Target', X_train_te_scaled, X_test_te_scaled)]:\n",
        "    for s in solvers:\n",
        "        for r_name, l1_r in reg_types.items():\n",
        "\n",
        "            print(f\"Running: Encoding={enc_name}, Solver={s}, Reg={r_name}\")\n",
        "\n",
        "            model = MyBinaryLogisticRegression(\n",
        "                solver=s,\n",
        "                l1_ratio=l1_r,\n",
        "                alpha=0.1,\n",
        "                iters=1000,\n",
        "                lr=0.01\n",
        "            )\n",
        "\n",
        "            try:\n",
        "                model.fit(X_train_scaled, y_train)\n",
        "                preds = model.predict(X_test_scaled.values)\n",
        "                f1 = f1_score(y_test, preds)\n",
        "\n",
        "                results.append({\n",
        "                    'Encoding': enc_name,\n",
        "                    'Solver': s,\n",
        "                    'Reg': r_name,\n",
        "                    'F1-Score': round(f1, 4)\n",
        "                })\n",
        "            except Exception as e:\n",
        "                print(f\"Error with Encoding={enc_name}, Solver={s}, Reg={r_name}: {e}\")\n",
        "\n",
        "\n",
        "res_df = pd.DataFrame(results)\n",
        "print(\"\\n--- Результаты классификации ---\")\n",
        "print(res_df.sort_values(by='F1-Score', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzbPWBevBfDg",
        "outputId": "ef0e89ca-9200-4389-90a3-75c431648a0f"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: Encoding=OHE, Solver=gd, Reg=l2\n",
            "Running: Encoding=OHE, Solver=gd, Reg=l1\n",
            "Running: Encoding=OHE, Solver=gd, Reg=l1l2\n",
            "Running: Encoding=OHE, Solver=sgd, Reg=l2\n",
            "Running: Encoding=OHE, Solver=sgd, Reg=l1\n",
            "Running: Encoding=OHE, Solver=sgd, Reg=l1l2\n",
            "Running: Encoding=OHE, Solver=newton, Reg=l2\n",
            "Running: Encoding=OHE, Solver=newton, Reg=l1\n",
            "Running: Encoding=OHE, Solver=newton, Reg=l1l2\n",
            "Running: Encoding=Target, Solver=gd, Reg=l2\n",
            "Running: Encoding=Target, Solver=gd, Reg=l1\n",
            "Running: Encoding=Target, Solver=gd, Reg=l1l2\n",
            "Running: Encoding=Target, Solver=sgd, Reg=l2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1909001358.py:92: UserWarning: Newton's method is not directly suited for L1 regularization. Only the L2 part of Elastic Net will be included in the Hessian matrix.\n",
            "  warnings.warn(\"Newton's method is not directly suited for L1 regularization. \"\n",
            "/tmp/ipython-input-1909001358.py:92: UserWarning: Newton's method is not directly suited for L1 regularization. Only the L2 part of Elastic Net will be included in the Hessian matrix.\n",
            "  warnings.warn(\"Newton's method is not directly suited for L1 regularization. \"\n",
            "/tmp/ipython-input-1909001358.py:115: UserWarning: Hessian matrix is singular, stopping Newton's method.\n",
            "  warnings.warn(\"Hessian matrix is singular, stopping Newton's method.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running: Encoding=Target, Solver=sgd, Reg=l1\n",
            "Running: Encoding=Target, Solver=sgd, Reg=l1l2\n",
            "Running: Encoding=Target, Solver=newton, Reg=l2\n",
            "Running: Encoding=Target, Solver=newton, Reg=l1\n",
            "Running: Encoding=Target, Solver=newton, Reg=l1l2\n",
            "\n",
            "--- Результаты классификации ---\n",
            "   Encoding  Solver   Reg  F1-Score\n",
            "14   Target     sgd  l1l2    0.7083\n",
            "9    Target      gd    l2    0.6809\n",
            "12   Target     sgd    l2    0.6809\n",
            "15   Target  newton    l2    0.6809\n",
            "13   Target     sgd    l1    0.6557\n",
            "1       OHE      gd    l1    0.6557\n",
            "10   Target      gd    l1    0.6557\n",
            "2       OHE      gd  l1l2    0.6557\n",
            "8       OHE  newton  l1l2    0.6557\n",
            "4       OHE     sgd    l1    0.6557\n",
            "11   Target      gd  l1l2    0.6557\n",
            "7       OHE  newton    l1    0.6364\n",
            "16   Target  newton    l1    0.6222\n",
            "5       OHE     sgd  l1l2    0.5926\n",
            "3       OHE     sgd    l2    0.5778\n",
            "0       OHE      gd    l2    0.5652\n",
            "6       OHE  newton    l2    0.5652\n",
            "17   Target  newton  l1l2    0.2632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1909001358.py:92: UserWarning: Newton's method is not directly suited for L1 regularization. Only the L2 part of Elastic Net will be included in the Hessian matrix.\n",
            "  warnings.warn(\"Newton's method is not directly suited for L1 regularization. \"\n",
            "/tmp/ipython-input-1909001358.py:115: UserWarning: Hessian matrix is singular, stopping Newton's method.\n",
            "  warnings.warn(\"Hessian matrix is singular, stopping Newton's method.\")\n",
            "/tmp/ipython-input-1909001358.py:92: UserWarning: Newton's method is not directly suited for L1 regularization. Only the L2 part of Elastic Net will be included in the Hessian matrix.\n",
            "  warnings.warn(\"Newton's method is not directly suited for L1 regularization. \"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Теоретическая часть"
      ],
      "metadata": {
        "id": "3d6yFdiJKh9M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пусть данные имеют вид\n",
        "$$\n",
        "(x_i, y_i), \\quad y_i \\in \\{1, \\ldots,M\\}, \\quad i \\in \\{1, \\ldots, N\\},\n",
        "$$\n",
        "причем первая координата набора признаков каждого объекта равна $1$.\n",
        "Используя `softmax`-подход, дискриминативная модель имеет следующий вид\n",
        "$$\n",
        "\\mathbb P(C_k|x) = \\frac{\\exp(\\omega_k^Tx)}{\\sum_i \\exp(\\omega_i^Tx)}.\n",
        "$$\n",
        "Для написания правдоподобия удобно провести `one-hot` кодирование меток класса, сопоставив каждому объекту $x_i$ вектор $\\widehat y_i = (y_{11}, \\ldots, y_{1M})$ длины $M$, состоящий из нулей и ровно одной единицы ($y_{iy_i} = 1$), отвечающей соответствующему классу. В этом случае правдоподобие имеет вид\n",
        "$$\n",
        "\\mathbb P(D|\\omega) = \\prod_{i = 1}^{N}\\prod_{j = 1}^M \\mathbb P(C_j|x_i)^{y_{ij}}.\n",
        "$$\n",
        "Ваша задача: вывести функцию потерь, градиент и гессиан для многоклассовой логистической регрессии. Реализовать матрично. На синтетическом примере продемонстрировать работу алгоритма, построить гиперплоскости, объяснить классификацию"
      ],
      "metadata": {
        "id": "03EZdWBHKotA"
      }
    }
  ]
}